# Vector Quantized Contrastive Predictive Coding for Template-based Music Generation
Gaëtan Hadjeres, Sony CSL, Paris, France (gaetan.hadjeres@sony.com)\
Léopold Crestel, Sony CSL, Paris, France (leopold.crestel@sony.com)

This is the companion github of the paper 
[Vector Quantized Contrastive Predictive Coding for Template-based Music Generation](www.google.com).
See also [https://sonycslparis.github.io/vqcpc-bach/](https://sonycslparis.github.io/vqcpc-bach/) for observeing our results.

## Installation
To install
- clone the repository.
- run (we recommend using a virtualenv) 
        
        pip install -r requirements.txt

## How to use it
All the experiments reported here can be reproduced with the different configuration files located in VQCPCB/configs.

Encoders are trained independently from the decode, in a self-supervised manner.
To train a particular encoder, run the following command

    python main_encoder.py -t -c VQCPCB/configs/encoder_*.py

with encoder_* being the name of the configuration file. 

Trained models are stored in *models/*.
To observe the clusters learned by a trained encoder, you can run the command

    python main_encoder.py -l -c models/encoder_*/config.py
    
To train a decoder for a particular encoder, you can run

    python main_decoder.py -t -c VQCPCB/configs/decoder_*.py 
    
after having specified in the configuration file VQCPCB/configs/decoder_*.py the path to the encoder:

    'config_encoder':              'models/encoder_*/config.py',
    
Variations of chorales excerpts 
as well as the complete re-harmonisation of all the chorales found in our corpus can be generated by running

    python main_decoder.py -l -c models/decoder_*/config.py 

## Experiments
### Clusters
- Sounds
- 3D map
- few words about how the different methods lead to clustering based on different features

|       |  Random | Same sequence | Student  
| :--- |:---:| :---: | :---:
| LSTM | !audio[ title ]( url ){ size=10 duration=10 cycle=forever } | | X
| Transformer | | |
| LSTM and no quantization | | | X
| Transformer and no quantization |  | | 

### Template-based generation
QUOI MONTRER
- tests perceptifs
    Q = extrait préféré
    Q = lequel respecte le mieux la structure d'origine
- petits fragments original // 3 variations
- rewritting d'un chorale complet

Parameters encoder
- Negative sampling scheme + student
- Quantization bottleneck
- Type of downsampling

Decoding is done with a relative transformer (**DESCRIBED IN PAPER**)

**ON MET DES SAMPLES DANS LES CASES**

|       |  Random | Same sequence | Student  
| :--- |:---:| :---: | :---:
| LSTM | | | X
| Transformer | | |
| LSTM and no quantization | | | X
| Transformer and no quantization |  | | 

Parameters decoder
- Models Baseline_Transfo ; AC//D//C ; F//F//C ; AC//AC//C
- top-k sampling

|       |  Transformer | Relative transformer  
| :--- |:---:| :---:
| Random |  | 
| Same sequence |  |
